library(tidycensus)
library(tidyverse)
library(sf)
library(ggplot2)
library(tmap)
library(tmaptools)
library(leaflet)
library(raster)
library(RColorBrewer)
library(mapview)
library(leaflet)
library(plotly)
library(lubridate)
v1 <- read_csv2("C:/Users/14145/Documents/GitHub/MUSA_550/MUSA-Practicum-Philly-Loading-Zone/Result_Prep_Java/testresult_0420.csv")
v1 <- read_csv2("C:/Users/14145/Documents/GitHub/MUSA_550/MUSA-Practicum-Philly-Loading-Zone/Result_Prep_Java/testresult_0420.csv", sep=",")
v1 <- read.csv("C:/Users/14145/Documents/GitHub/MUSA_550/MUSA-Practicum-Philly-Loading-Zone/Result_Prep_Java/testresult_0420.csv", sep=",")
glimpse(v1)
# Chunk 1: setup
knitr::opts_chunk$set(echo = TRUE,warning = FALSE, message = FALSE)
# Chunk 2
# You can set some global options for knitting chunks
knitr::opts_chunk$set(echo = TRUE)
# Load some libraries
library(tidyverse)
library(tidycensus)
library(sf)
library(spdep)
library(caret)
library(ckanr)
library(FNN)
library(grid)
library(gridExtra)
library(ggcorrplot) # plot correlation plot
library(corrr)      # another way to plot correlation plot
library(kableExtra)
library(broom)
library(tufte)
library(rmarkdown)
library(hexbin)
library(viridis)
library(cbsodataR)
library(jtools)     # for regression model plots
library(ggstance) # to support jtools plots
library(ggpubr)    # plotting R^2 value on ggplot point scatter
library(broom.mixed) # needed for effects plots
library(stargazer)
library(jsonlite)
library(ggplot2)
library(tmap)
library(tmaptools)
library(leaflet)
library(raster)
library(RColorBrewer)
library(mapview)
library(leaflet)
library(plotly)
library(ggspatial)
library(openxlsx)
library(lubridate)
library(dplyr)
library(tidyr)
library(reshape2)
library(riem)
library(jsonlite)
library(readr)
library(httr)
library(tidymodels)
library(randomForest)
library(vip)
library(pROC)
#library(rjson)
# functions and data directory
source("https://raw.githubusercontent.com/urbanSpatial/Public-Policy-Analytics-Landing/master/functions.r")
palette2 <- c('#3E4A89','#1F9E89')
palette4 <- c('#3E4A89','#1F9E89','#35B779','#B4DE2C')
palette5 <- c('#440154','#3E4A89','#1F9E89','#35B779','#B4DE2C')
palette6 <- c('#440154','#3E4A89','#1F9E89','#35B779','#B4DE2C','#FDE725')
palette10 <- c('#440154','#482777','#3E4A89','#31688E','#26828E','#1F9E89','#35B779','#6DCD59','#B4DE2C','#FDE725')
# Chunk 3: input data
coords_raw <- read.csv("https://raw.githubusercontent.com/YueqiTiffanyLuo/MUSA-Practicum-Philly-Loading-Zone/main/Data%20Used/Ling/Old_Data_for_Testing/zoneCoords.csv")
# split coords
coords_split <- strsplit(coords_raw$coords, ",")
coords_raw$latitude <- as.numeric(sapply(coords_split, `[`, 1))
coords_raw$longitude <- as.numeric(sapply(coords_split, `[`, 2))
# create coords shapefile
coords <- st_as_sf(coords_raw, coords = c("longitude", "latitude"), crs = 'ESRI:102729')
# Read Linear Assets
## Base URL for the shapefile components
base_url <- "https://raw.githubusercontent.com/YueqiTiffanyLuo/MUSA-Practicum-Philly-Loading-Zone/main/Data%20Used/Ling/resmartloadingzones/Curb_and_Asset_Shapefiles/"
## List of file extensions for a shapefile
extensions <- c("shp", "shx", "dbf", "prj")
## Create a temporary directory to store files
temp_dir <- tempdir()
## Download each component
for (ext in extensions) {
file_url <- paste0(base_url, "linear_assets.", ext)
download.file(file_url, destfile = file.path(temp_dir, paste0("linear_assets.", ext)), mode = "wb")
}
## Read the shapefile
filepath <- file.path(temp_dir, "linear_assets.shp")
linAssets <- st_read(filepath)
linAssets <- st_transform(linAssets, crs = "ESRI:102729")
# load booking data
booking_data <- st_read("https://raw.githubusercontent.com/YueqiTiffanyLuo/MUSA-Practicum-Philly-Loading-Zone//main/Data%20Used/Booking%20Data_cleaned.geojson")
# load curb zone data
curb_zone <- fromJSON("https://raw.githubusercontent.com/YueqiTiffanyLuo/MUSA-Practicum-Philly-Loading-Zone/main/Data%20Used/Ling/resmartloadingzones/curb_zones.json")
# load CDS event data
event_export <- read.csv("https://github.com/YueqiTiffanyLuo/MUSA-Practicum-Philly-Loading-Zone/blob/main/Data%20Used/Ling/events_export_CDS.csv")
# load regulation geojson
regulations <- st_read("https://raw.githubusercontent.com/YueqiTiffanyLuo/MUSA-Practicum-Philly-Loading-Zone/main/Data%20Used/Ling/resmartloadingzones/regulations.geojson")
# Road Data
completestreets <- st_read("https://raw.githubusercontent.com/YueqiTiffanyLuo/MUSA-Practicum-Philly-Loading-Zone/main/Data%20Used/FilteredStreets.geojson")
bike_network <- st_read("https://raw.githubusercontent.com/YueqiTiffanyLuo/MUSA-Practicum-Philly-Loading-Zone/main/Data%20Used/Bike_Network.geojson")
simple_panel <- read_csv("https://raw.githubusercontent.com/YueqiTiffanyLuo/MUSA-Practicum-Philly-Loading-Zone/main/Data%20Used/03_31_panel.csv")
test <- st_read("https://raw.githubusercontent.com/YueqiTiffanyLuo/MUSA-Practicum-Philly-Loading-Zone/main/Data%20Used/Ling/zones_nn_3.geojson")
#Bookings
curbs <- st_read("https://raw.githubusercontent.com/YueqiTiffanyLuo/MUSA-Practicum-Philly-Loading-Zone/main/Data%20Used/Ling/all_curbs_0415.geojson")
offices <- st_read("https://raw.githubusercontent.com/YueqiTiffanyLuo/MUSA-Practicum-Philly-Loading-Zone/main/Data%20Used/Ling/offices.geojson")
sf_amenities <- st_read("https://raw.githubusercontent.com/YueqiTiffanyLuo/MUSA-Practicum-Philly-Loading-Zone/main/Data%20Used/Ling/amenities.geojson")%>%
st_transform(2272)
sf_buildings <- st_read("https://raw.githubusercontent.com/YueqiTiffanyLuo/MUSA-Practicum-Philly-Loading-Zone/main/Data%20Used/Ling/buildings.geojson")%>%
st_transform(2272)
sf_landuse <- st_read("https://raw.githubusercontent.com/YueqiTiffanyLuo/MUSA-Practicum-Philly-Loading-Zone/main/Data%20Used/Ling/landuse.geojson")
sf_shops <- st_read("https://raw.githubusercontent.com/YueqiTiffanyLuo/MUSA-Practicum-Philly-Loading-Zone/main/Data%20Used/Ling/shops.geojson")%>%
st_transform(2272) %>%
mutate(shop = ifelse(shop == "coffee", "beverages", shop)) %>%
mutate(shop = ifelse(shop == "general", "convenience", shop))
sf_offices <- st_read("https://raw.githubusercontent.com/YueqiTiffanyLuo/MUSA-Practicum-Philly-Loading-Zone/main/Data%20Used/Ling/offices.geojson")%>%
st_transform(2272)
bookings <- st_read("https://raw.githubusercontent.com/YueqiTiffanyLuo/MUSA-Practicum-Philly-Loading-Zone//main/Data%20Used/Booking%20Data_cleaned.geojson") %>%
st_transform(2272)
#All Curbs
## Base URL for the shapefile components
base_url1 <- "https://raw.githubusercontent.com/YueqiTiffanyLuo/MUSA-Practicum-Philly-Loading-Zone/main/Data%20Used/Ling/curbs_road_type/"
## List of file extensions for a shapefile
extensions1 <- c("shp", "shx", "dbf", "prj")
## Create a temporary directory to store files
temp_dir1 <- tempdir()
## Download each component
for (ext in extensions) {
file_url1 <- paste0(base_url1, "all_curbs_road_type.", ext)
download.file(file_url1, destfile = file.path(temp_dir1, paste0("all_curbs_road_type.", ext)), mode = "wb")
}
## Read the shapefile
filepath1 <- file.path(temp_dir1, "all_curbs_road_type.shp")
all_curbs <- st_read(filepath1)%>%
dplyr::select(TARGET_FID, end_st_, strt_s_, strt_nm, CLASS_2, geometry) %>%
rename(Road_Class = CLASS_2) %>%
st_transform(2272)
#Road Class
## Base URL for the shapefile components
base_url2 <- "https://raw.githubusercontent.com/YueqiTiffanyLuo/MUSA-Practicum-Philly-Loading-Zone/main/Data%20Used/Ling/curbs_road_type/"
## List of file extensions for a shapefile
extensions2 <- c("shp", "shx", "dbf", "prj")
## Create a temporary directory to store files
temp_dir2 <- tempdir()
## Download each component
for (ext in extensions) {
file_url2 <- paste0(base_url2, "all_curbs_road_type.", ext)
download.file(file_url2, destfile = file.path(temp_dir2, paste0("simple_road_classes.", ext)), mode = "wb")
}
## Read the shapefile
filepath2 <- file.path(temp_dir2, "simple_road_classes.shp")
road_classes <- st_read(filepath2)%>%
st_transform(2272)
# Write road class to GeoJSON file
all_curbs <- st_read("https://raw.githubusercontent.com/YueqiTiffanyLuo/MUSA-Practicum-Philly-Loading-Zone/main/Data%20Used/Ling/all_curbs_0411.geojson")
og_panel <- read.csv("https://raw.githubusercontent.com/YueqiTiffanyLuo/MUSA-Practicum-Philly-Loading-Zone/main/Data%20Used/Ling/first_panel.csv")
new_cats <- read.csv("https://raw.githubusercontent.com/YueqiTiffanyLuo/MUSA-Practicum-Philly-Loading-Zone/main/Data%20Used/Ling/new_categories.csv")
merged_df <- read.csv("https://raw.githubusercontent.com/YueqiTiffanyLuo/MUSA-Practicum-Philly-Loading-Zone/main/Data%20Used/zones_with_simple_nns.csv")
first_panel <- st_read("https://raw.githubusercontent.com/YueqiTiffanyLuo/MUSA-Practicum-Philly-Loading-Zone/main/Data%20Used/Ling/finalpanel.geojson")
zones <- read.csv("https://raw.githubusercontent.com/YueqiTiffanyLuo/MUSA-Practicum-Philly-Loading-Zone/main/Data%20Used/zones_with_simple_nns.csv")
panel_0326 <- read.csv("https://raw.githubusercontent.com/YueqiTiffanyLuo/MUSA-Practicum-Philly-Loading-Zone/main/Old_Geojson_Panel/03-26_first_panel.csv")
road_class <- read.csv("https://raw.githubusercontent.com/YueqiTiffanyLuo/MUSA-Practicum-Philly-Loading-Zone/main/Data%20Used/Ling/first_panel.csv")
og_panel <- read.csv("https://raw.githubusercontent.com/YueqiTiffanyLuo/MUSA-Practicum-Philly-Loading-Zone/main/Data%20Used/Ling/first_panel.csv")
new_cats <- read.csv("https://raw.githubusercontent.com/YueqiTiffanyLuo/MUSA-Practicum-Philly-Loading-Zone/main/Data%20Used/Ling/new_categories.csv")
#merged_df2 <- st_read("https://raw.githubusercontent.com/YueqiTiffanyLuo/MUSA-Practicum-Philly-Loading-Zone/main/Data%20Used/Ling/all_curbs_0415.geojson")
panel <- st_read("https://raw.githubusercontent.com/YueqiTiffanyLuo/MUSA-Practicum-Philly-Loading-Zone/main/04_29_reduced_panel.geojson")
geo <- read.csv("https://raw.githubusercontent.com/YueqiTiffanyLuo/MUSA-Practicum-Philly-Loading-Zone/main/Data%20Used/Ling/geometry.csv")
try <- read_sf("https://raw.githubusercontent.com/YueqiTiffanyLuo/MUSA-Practicum-Philly-Loading-Zone/main/Data%20Used/Ling/finalpanel.geojson")
add <- read_sf("https://raw.githubusercontent.com/YueqiTiffanyLuo/MUSA-Practicum-Philly-Loading-Zone/main/Data%20Used/Ling/add.geojson")
road_class <- read_sf("https://raw.githubusercontent.com/YueqiTiffanyLuo/MUSA-Practicum-Philly-Loading-Zone/main/Data%20Used/Ling/bookings_road_class_nn.geojson")
all_curbs <- read_sf("https://raw.githubusercontent.com/YueqiTiffanyLuo/MUSA-Practicum-Philly-Loading-Zone/main/Data%20Used/Ling/all_curbs_0415.geojson")
all_curbs_nn <- read_sf("https://raw.githubusercontent.com/YueqiTiffanyLuo/MUSA-Practicum-Philly-Loading-Zone/main/Data%20Used/Ling/all_curbs_nn.geojson")
polygon <- read_sf("https://raw.githubusercontent.com/YueqiTiffanyLuo/MUSA-Practicum-Philly-Loading-Zone/main/Data%20Used/Ling/OSM_bounding_box.geojson")
# Chunk 4
utilization <- booking_data %>%
dplyr::select(SmartZoneName,OMFCurbZoneID,EventType,ViolationType,VehicleType,TimeRequestedHour,Amount,geometry)
utilization$OMFCurbZoneID <- substr(utilization$OMFCurbZoneID, nchar(utilization$OMFCurbZoneID)-2, nchar(utilization$OMFCurbZoneID))
curb_geom<- utilization %>%
select(SmartZoneName,OMFCurbZoneID,geometry) %>%
group_by(SmartZoneName,OMFCurbZoneID) %>%
summarise(Events=n())
# Chunk 5: timesegment
utilization$DwellTimeMinutes <- utilization$TimeRequestedHour * 60
utilization$TimeSegment <- cut(utilization$DwellTimeMinutes,
breaks = c(0, 5, 15, 30, 45, 61),
labels = c("0-5", "6-15", "16-30", "31-45","46-60"),
right = FALSE)
utilization <- utilization %>%
mutate(TimeSegment = as.character(TimeSegment), # Convert factor to character
TimeSegment = replace_na(TimeSegment, "violation")) # Replace NA with "violation"
utilization$TimeSegment <- factor(utilization$TimeSegment)
utilization <- utilization %>%
mutate(ViolationType = ifelse(ViolationType == "", "booking", ViolationType))
# Chunk 6
# dwell time - min
grid.arrange(
ggplot(utilization, aes(x = DwellTimeMinutes)) + geom_histogram(bins = 20, fill = "#440154", color = "white") +
labs(title = "Dwell Time Distribution", x = "Dwell Time (minutes)", y = "Frequency")+
theme_minimal(),
ggplot(utilization, aes(x = TimeSegment)) +
geom_bar(fill = "#440154", color = "white") +
theme_minimal() +
labs(title = "Counts by Time Segment", x = "Time Segment", y = "Count") +
theme_minimal(),
# vehicle type:commercial/medium commercial/other/truck
ggplot(utilization, aes(x = VehicleType)) + geom_bar(fill = "#440154") +
labs(title = "Vehicle Type Distribution", x = "Vehicle Type", y = "Count")+
theme_minimal(),
# vehicle type: car/freight/truck/van
ggplot(utilization, aes(x = EventType)) + geom_bar(fill = "#440154") +
labs(title = "Event Type Distribution", x = "Event Type", y = "Count")+
theme_minimal(),
nrow=2)
# Chunk 7
# Availability of curb zones
# vehicle count by curb zone and tiem segment
availability_analysis <- utilization %>%
group_by(OMFCurbZoneID, TimeSegment) %>%
summarise(VehicleCount = n())
ggplot(availability_analysis, aes(x = OMFCurbZoneID, y = VehicleCount, fill = TimeSegment)) +
geom_bar(stat = "identity", position = "dodge") +
theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
scale_fill_manual(values = palette6)+
labs(title = "Vehicle Count by Curb Zone and Time Segment", x = "Curb Zone ID", y = "Vehicle Count")
# violation type distribution by curb zone
violation_analysis <- utilization %>%
group_by(OMFCurbZoneID, ViolationType) %>%
summarise(Count = n())
ggplot(violation_analysis, aes(x = OMFCurbZoneID, y = Count, fill = ViolationType)) +
geom_bar(stat = "identity", position = "dodge") +
theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
scale_fill_manual(values = palette6)+
labs(title = "Violation Type Distribution by Curb Zone", x = "Curb Zone ID", y = "Count")
# Chunk 8: dwelltime_withviolation
utilization_sf <- st_as_sf(utilization, wkt = "geometry", crs = 4326)
# Assuming your data is in a dataframe called 'data'
# Calculate the most frequent TimeSegment for each SmartZoneName
most_freq_time_segments <- utilization %>%
count(SmartZoneName, TimeSegment) %>%
group_by(SmartZoneName) %>%
filter(n == max(n)) %>%
slice(1) %>% # In case there are ties, take the first
ungroup()
# Set tmap mode to view for interactive maps
tmap_mode("view")
# Visualize using tmap
tm0 <- tm_shape(most_freq_time_segments) +
tm_symbols(col = "TimeSegment", size = 10, border.col = "black", palette = "viridis",
title.col = "Most Frequent TimeSegment") +
tm_layout(title = "Most Frequent TimeSegments by SmartZoneCurb")
tm0
# Chunk 9: dwelltime_withoutviolation
most_freq_time_withoutviolation <- utilization %>%
filter(TimeSegment != "violation") %>%
count(SmartZoneName, TimeSegment) %>%
group_by(SmartZoneName) %>%
filter(n == max(n)) %>%
slice(1) %>% # In case there are ties, take the first
ungroup()
tmap_mode("view")
tm1 <- tm_shape(most_freq_time_withoutviolation) +
tm_symbols(col = "TimeSegment", size = 10, border.col = "black", palette = "viridis",
title.col = "Most Frequent TimeSegment") +
tm_layout(title = "Most Frequent TimeSegments by SmartZoneCurb(excluding violations)")
tm1
# Chunk 10: id_clean
event_export$curb_zone_id <- substr(event_export$curb_zone_id, nchar(event_export$curb_zone_id)-2, nchar(event_export$curb_zone_id))
